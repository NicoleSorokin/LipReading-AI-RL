# Project Overview

In this folder, you will find code for the following stages:

## Stage 1: Lip Reading and Body Language Analysis
- **Lip Reading to Text**: Uses the LipNet model for converting lip movements to text, involving facial landmark detection, preprocessing, and model training on sequences of frames.
- **Emotion Detection from Body Language and Lips**: Implements the EMOLIPS model (CNN-LSTM) for detecting emotions based on lip movements and body language analysis with Mediapipe, focusing on differentiating between threatening and non-threatening behaviors.

## Stage 2: Reinforcement Learning
- This stage involves reinforcement learning techniques to improve the model's accuracy and adaptability in detecting emotions and behaviors. The RL model will be trained to refine threat identification based on feedback loops and continuous learning.

---

Each stage includes relevant scripts, models, and data preprocessing techniques. Follow the README files in each subfolder for detailed instructions on usage and setup.
